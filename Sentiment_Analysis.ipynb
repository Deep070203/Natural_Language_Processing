{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4872e3",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bd65f6",
   "metadata": {},
   "source": [
    "It is a popular embedding technique that uses neural networks.\n",
    "\n",
    "Words are mapped to vectors usch that words occuring in similar context are grouped closer together in the graph space.\n",
    "\n",
    "In sentiment analysis, these embedding allow algoithms to understand the meaning of words based on their context within the text enabling the model to discern nuances and sentiment by recogninzing similarities and differences b/w words.\n",
    "\n",
    "It implements two different architectures:\n",
    "    \n",
    "    1. Skip-Gram:  which implements and predicts thesorrounding words given a target word. This captures word relationships based on how likely a word is to appear in a specific context.\n",
    "    \n",
    "    2. Continuous Bag-Of-Words (CBOW): This predicts the target word based on the sorrounding context in a window size of N words. It captures semantic relationships based on how words co-occur within a specific local context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d326e8",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce581f",
   "metadata": {},
   "source": [
    "It is an unsupervised learning algorithm for obtaining vector respresentation of words by aggregating global word-to-word co-occurance statistics from a corpus.\n",
    "\n",
    "It focuses on the global statistical information of a corpus to learn word embeddings.\n",
    "\n",
    "It directly captures relationships between words based on their co-occurence probabilities over the entire corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455e229",
   "metadata": {},
   "source": [
    "## Deep Learning for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c349b7",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f106c",
   "metadata": {},
   "source": [
    "They are designed for sequential data like language or time series. RNNs retain information from previous steps and are thus ideal for language modeling and speech recognition. \n",
    "\n",
    "Functioning step-by-step, RNNs maintain a hidden state as a memory updated with input and prior hidden states. They share weights accross different steps, facilitating information sharing to build a numeric-based understanding of context.\n",
    "\n",
    "The main challenge lies in learning long-range dependencies. This is where we have a large body of text that we want to analyze, and  there is simply too much data to keep track of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e3f61",
   "metadata": {},
   "source": [
    "### Long Short-term Memory Networks (LSTMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b18c2",
   "metadata": {},
   "source": [
    "This is to tackle RNNs problem.\n",
    "\n",
    "These provide mechanisms to allow RNNs to keep track of the smenatic meaning of text over very large blocks of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c05f0e",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51428c",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall, F1-score, Receiver Operating Characteristic (ROC) Curve (evaluates binary classifers accross varying thresholds and plots the true positive rates against false positive rates), Area under the curve (AUC) interprets the ROC curve's performance.\n",
    "\n",
    "TP = True Positive, TN = True Negative, FP = False Positive, FN = False Negative \n",
    "\n",
    "Accuracy = (TP + TN)/(TP+TN+FP+FN)\n",
    "\n",
    "Precision = TP/(TP+FP)\n",
    "\n",
    "Recall = TP/(TP+FN)\n",
    "\n",
    "F1 Score = 2 * ( (Precision * Recall)/(Precision + Recall) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cd0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
